# Phase 3: Analysis Execution

**Objective**: Execute the generated Python script and interpret the results to provide actionable insights.

---

## ‚ñ∂Ô∏è Execute the Analysis Script

**Use MCP Tool**: `execute_analysis_script`

**Required Parameters:**
- `script_path`: Path to your generated script (e.g., `analytics/parse_logs_20251128_165500.py`)
- `log_data_path`: Path to log data (default: `analytics/incident_logs.json`)

**Example:**
```
execute_analysis_script(
  script_path="analytics/parse_logs_20251128_165500.py",
  log_data_path="analytics/incident_logs.json"
)
```

**Expected Response:**
- Status: "success" or "error"
- Output: JSON results from your script
- Execution time

---

## üìä Interpret the Results

Once the script executes successfully, analyze the output:

### 1. **Summary Statistics**

Review the high-level metrics:
- Total logs processed
- Total errors detected
- Error rate percentage
- Total warnings

**Questions to answer:**
- Is the error rate abnormally high (> 1%)?
- Are warnings also elevated?
- What's the baseline error rate for this system?

### 2. **Error Pattern Analysis**

Examine the top error codes:
- Which error is most frequent?
- Are errors concentrated in specific error types?
- Do error codes indicate a common root cause?

**Example Interpretation:**
```
If "AUTH_TIMEOUT" represents 60% of errors AND
"REDIS_TIMEOUT" represents 30% of errors
‚Üí Likely root cause: Redis connection pool exhaustion affecting auth service
```

### 3. **Service-Level Breakdown**

Identify which services are most affected:
- Which service has the highest error count?
- Are errors isolated to one service or cascading?
- Is there a dependency chain being impacted?

**Example Interpretation:**
```
If auth-service has 60% of errors AND
session-store has 30% of errors
‚Üí auth-service depends on session-store
‚Üí session-store failure is cascading to auth-service
```

### 4. **Time-Series Patterns**

Analyze when errors occur:
- What hour has the peak error count?
- Is there a sudden spike or gradual increase?
- Does this correlate with known events (deploys, traffic patterns)?

**Example Interpretation:**
```
If errors spiked at hour 14 (2 PM) AND
Error rate went from 0.1% to 5% in 1 hour
‚Üí Sudden onset incident (not gradual degradation)
‚Üí Likely triggered by a specific event at ~2 PM
```

### 5. **Performance Metrics**

Review response time statistics:
- Is P95/P99 response time elevated?
- Which services have the slowest response times?
- Are slow responses correlated with errors?

**Example Interpretation:**
```
If P95 response time is 5000ms (5s) AND
Errors show "timeout" messages
‚Üí System is timing out due to slow performance
‚Üí Root cause is likely resource contention or downstream service degradation
```

### 6. **Detected Anomalies**

Review any anomalies identified by the script:
- Which services have abnormally high error rates?
- Are there endpoints with unusual behavior?
- What severity level are the anomalies?

---

## üéØ Synthesize Findings

Based on the analysis results, provide:

### **Key Insights:**
1. **Primary Error Type**: [Most frequent error code and its percentage]
2. **Affected Services**: [Services with highest error counts]
3. **Time Pattern**: [When did errors spike? Gradual or sudden?]
4. **Performance Impact**: [P95/P99 response times and their impact]

### **Root Cause Hypothesis:**
Based on error patterns, service dependencies, and timing:
- [State your hypothesis with confidence level]

### **Recommended Actions:**
1. **Immediate**: [Actions to take now to mitigate]
2. **Short-term**: [Actions to resolve root cause]
3. **Long-term**: [Preventive measures]

---

## üíæ Save Analysis Results

**Use Write Tool**: Save the script output for documentation

**CRITICAL - File Path MUST BE**: `analytics/analysis_results_[TIMESTAMP].json`

**üö® MANDATORY - FILE PATH MUST BE IN PROJECT DIRECTORY:**

```python
# ‚úÖ CORRECT - Use this EXACT pattern:
from datetime import datetime
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
results_path = f"analytics/analysis_results_{timestamp}.json"  # Relative!

# ‚ùå FORBIDDEN - NEVER use:
results_path = "/tmp/analysis_results.json"      # WRONG!
results_path = "/private/tmp/results.json"       # WRONG!
```

**Rules:**
- ‚úÖ MUST be relative path starting with `analytics/`
- ‚úÖ MUST include timestamp
- ‚ùå NO `/tmp/` - Security risk and data loss
- ‚ùå NO absolute paths outside project

**Content**: The JSON output from the executed script

**Why?**
- Preserves analysis results for incident reports
- Allows comparison with future incidents
- Provides audit trail
- Keeps sensitive analysis data within secure project directory

**Verification:**
After saving, confirm the file path is: `/Users/<username>/CladeSkillDemo/analytics/analysis_results_*.json`
NOT `/tmp/` or `/private/tmp/`

---

## ‚úÖ Phase 3 Complete - Analysis Execution Summary

**Before completing the skill, confirm:**
- ‚úÖ Script executed successfully using `execute_analysis_script`
- ‚úÖ Results interpreted and insights documented
- ‚úÖ Root cause hypothesis formulated with confidence level
- ‚úÖ Recommended actions provided (immediate, short-term, long-term)
- ‚úÖ Analysis results saved to `analytics/analysis_results_[TIMESTAMP].json`

### **Final Deliverables:**

1. **Files Created:**
   - `analytics/incident_logs.json` - Raw log data
   - `analytics/parse_logs_[TIMESTAMP].py` - Analysis script
   - `analytics/analysis_results_[TIMESTAMP].json` - Analysis output

2. **Key Findings:**
   - Total logs analyzed: [NUMBER]
   - Error rate: [PERCENTAGE]
   - Top error: [ERROR_CODE] ([COUNT] occurrences)
   - Most affected service: [SERVICE_NAME]
   - Peak error time: [HOUR]

3. **Root Cause Hypothesis:**
   - [HYPOTHESIS] (confidence: [X]%)

4. **Recommended Actions:**
   - Immediate: [ACTION]
   - Short-term: [ACTION]
   - Long-term: [ACTION]

---

## üéâ Log Analytics Skill Complete

You've successfully:
- ‚úÖ Fetched large-scale log data
- ‚úÖ Generated custom Python analysis code
- ‚úÖ Executed the analysis and extracted insights
- ‚úÖ Provided actionable recommendations

**Next Step**: If this skill was invoked by another skill (e.g., `incident-analysis`), return control to that skill with your findings.

Otherwise, the log analytics workflow is complete.

