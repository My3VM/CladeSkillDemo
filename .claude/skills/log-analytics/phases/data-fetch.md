# Phase 1: Data Fetch

**Objective**: Retrieve raw log data for the incident and save it for analysis.

---

## üì• Fetch Raw Logs

**Use MCP Tool**: `get_raw_logs`

**Required Parameters:**
- `incident_id`: The incident ID you're analyzing (e.g., "INC-2025-001")
- `timeframe`: Time range to fetch (default: "1h", can use "24h", "7d")
- `service_filter`: Optional service name filter (default: "all")

**Example:**
```
get_raw_logs(
  incident_id="INC-2025-001",
  timeframe="1h",
  service_filter="all"
)
```

**Expected Response:**
- JSON object with 1000+ log entries
- Each entry contains: timestamp, level, service, message, response_time_ms, error_code, etc.
- Summary statistics (total errors, warnings, error rate)

---

## üíæ Save Log Data

**Use Write Tool**: Save the raw log data to disk

**CRITICAL - File Path MUST BE**: `analytics/incident_logs.json`

**üö® MANDATORY - FILE PATH MUST BE IN PROJECT DIRECTORY:**

```python
# ‚úÖ CORRECT - Use this EXACT path:
data_path = "analytics/incident_logs.json"  # Relative path!

# ‚ùå FORBIDDEN - NEVER use:
data_path = "/tmp/incident_logs.json"       # WRONG!
data_path = "/private/tmp/logs.json"        # WRONG!
```

**Rules:**
- ‚úÖ MUST be `analytics/incident_logs.json` (relative path)
- ‚ùå NO `/tmp/` - Security risk and data loss
- ‚ùå NO absolute paths outside project

**Why?**
- The generated Python script will read from this file
- Preserves raw data for auditing
- Allows re-running analysis without re-fetching
- Keeps sensitive log data within secure project directory

**Action:**
```
Write tool ‚Üí "analytics/incident_logs.json"
Content: The full JSON response from get_raw_logs
```

**Verification:**
After saving, confirm the file path is: `/Users/maivishw/ClaudeSkillsSDK/analytics/incident_logs.json`
NOT `/tmp/` or `/private/tmp/`

---

## üîç Inspect the Data Structure

Before moving to code generation, examine the log structure:

1. **What fields are present?** (timestamp, level, service, error_code, etc.)
2. **What error types exist?** (AUTH_TIMEOUT, REDIS_TIMEOUT, etc.)
3. **What services are logging?** (auth-service, session-store, etc.)
4. **What time range is covered?**

**Document your observations** - you'll need this for Phase 2.

---

## ‚úÖ Phase 1 Complete - Data Fetch Summary

**Before proceeding, confirm:**
- ‚úÖ Raw logs fetched using `get_raw_logs` tool
- ‚úÖ Log data saved to `analytics/incident_logs.json`
- ‚úÖ You've inspected the log structure and identified key fields
- ‚úÖ Total log entries: [STATE THE NUMBER]
- ‚úÖ Error rate: [STATE THE %]
- ‚úÖ Primary error codes identified: [LIST TOP 3]

---

## Next Step

Once log data is saved and inspected, proceed to Phase 2: Code Generation.

**Read**: `phases/code-generation.md` to continue.

